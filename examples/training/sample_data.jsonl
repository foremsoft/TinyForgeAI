{"input": "What is machine learning?", "output": "Machine learning is a type of artificial intelligence that allows computers to learn from data without being explicitly programmed. It enables systems to improve their performance through experience."}
{"input": "How does deep learning work?", "output": "Deep learning uses neural networks with many layers to learn complex patterns in data. Each layer transforms the input progressively, extracting higher-level features. This mimics how the human brain processes information."}
{"input": "What is a neural network?", "output": "A neural network is a computing system inspired by the human brain. It consists of interconnected nodes (neurons) organized in layers that process information and learn patterns from data."}
{"input": "Explain supervised learning", "output": "Supervised learning is a type of machine learning where the model learns from labeled examples. You provide input-output pairs, and the model learns to predict outputs for new inputs. It's like learning from a teacher who provides correct answers."}
{"input": "What is unsupervised learning?", "output": "Unsupervised learning finds patterns in data without labeled examples. The model discovers hidden structures on its own, like grouping similar items together or finding anomalies."}
{"input": "Define reinforcement learning", "output": "Reinforcement learning trains agents to make decisions by rewarding good actions and penalizing bad ones. The agent learns through trial and error, like teaching a robot to walk by encouraging steps and discouraging falls."}
{"input": "What is natural language processing?", "output": "Natural language processing (NLP) is the field of AI focused on enabling computers to understand, interpret, and generate human language. It powers chatbots, translation, and text analysis."}
{"input": "Explain transfer learning", "output": "Transfer learning uses knowledge from a model trained on one task to improve performance on a different but related task. It's like using your knowledge of Spanish to learn Italian faster."}
{"input": "What is overfitting?", "output": "Overfitting occurs when a model learns the training data too well, including its noise and errors. This causes poor performance on new, unseen data. It's like memorizing test answers without understanding the concepts."}
{"input": "How do you prevent overfitting?", "output": "Prevent overfitting by using more training data, applying regularization techniques, using dropout layers, implementing early stopping, or using simpler models. Cross-validation also helps detect overfitting."}
{"input": "What is a transformer model?", "output": "A transformer is a neural network architecture that uses self-attention to process sequences. It can look at all parts of an input simultaneously, making it excellent for language tasks. GPT and BERT are famous transformer models."}
{"input": "Explain attention mechanism", "output": "Attention allows models to focus on relevant parts of the input when producing output. Like how humans pay attention to certain words when reading, attention helps models weigh the importance of different input elements."}
{"input": "What is fine-tuning?", "output": "Fine-tuning adapts a pre-trained model to a specific task by training it on your custom data. It's more efficient than training from scratch because the model already knows general patterns."}
{"input": "What is gradient descent?", "output": "Gradient descent is an optimization algorithm that finds the best model parameters by iteratively moving in the direction of steepest decrease in error. It's like finding the bottom of a valley by always walking downhill."}
{"input": "Explain batch size", "output": "Batch size is the number of training examples processed together before updating model weights. Larger batches provide stable gradients but need more memory. Smaller batches add noise but can help escape local minima."}
