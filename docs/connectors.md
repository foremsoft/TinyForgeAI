# TinyForgeAI Connectors Documentation
<!-- Generated by Claude Code: Step I.1 -->

**Last updated:** 2025-01-15T00:00:00Z

This document describes the data source connectors available in TinyForgeAI for loading training data from various sources.

## Overview

The Data Connector Layer provides a unified interface for ingesting training data from multiple sources. Each connector follows a consistent pattern:

- **Programmatic API**: Python classes and functions for integration into custom pipelines
- **CLI Support**: Command-line tools for quick data extraction and testing
- **Mock Mode**: Offline development support via environment variables

### Supported Data Sources

| Source | Connector | Status | Mock Mode |
|--------|-----------|--------|-----------|
| SQL Databases | `DBConnector` | Implemented | N/A (use SQLite) |
| Google Docs | `google_docs_connector` | Implemented | `GOOGLE_OAUTH_DISABLED=true` |
| Local Files | `file_ingest` | Implemented | N/A |
| Google Drive | Planned | - | - |
| Notion | Planned | - | - |
| REST APIs | Planned | - | - |

### Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                     Data Sources                            │
│  ┌─────────┐  ┌─────────────┐  ┌───────────┐  ┌──────────┐ │
│  │ SQL DB  │  │ Google Docs │  │ Files     │  │ API/etc  │ │
│  └────┬────┘  └──────┬──────┘  └─────┬─────┘  └────┬─────┘ │
└───────┼──────────────┼───────────────┼─────────────┼───────┘
        │              │               │             │
        ▼              ▼               ▼             ▼
┌─────────────────────────────────────────────────────────────┐
│                   Connector Layer                           │
│  ┌─────────────┐ ┌───────────────────┐ ┌─────────────────┐ │
│  │DBConnector  │ │google_docs_connect│ │file_ingest      │ │
│  │             │ │                   │ │                 │ │
│  │stream_sample│ │fetch_doc_text()   │ │ingest_file()    │ │
│  └──────┬──────┘ └─────────┬─────────┘ └────────┬────────┘ │
└─────────┼──────────────────┼────────────────────┼──────────┘
          │                  │                    │
          ▼                  ▼                    ▼
┌─────────────────────────────────────────────────────────────┐
│                  Training Samples (JSONL)                   │
│       {"input": "...", "output": "...", "metadata": {...}}  │
└─────────────────────────────────────────────────────────────┘
```

## Database Connector

The database connector streams training samples directly from SQL databases. It uses Python's built-in `sqlite3` module for SQLite databases.

### Quick Start

```python
from connectors.db_connector import DBConnector

# Create connector (uses DB_URL from environment by default)
conn = DBConnector(db_url="sqlite:///./data/qa.db")

# Test connection
if conn.test_connection():
    print("Connected successfully!")

# Stream training samples
query = "SELECT question, answer FROM qa_pairs"
mapping = {"input": "question", "output": "answer"}

for sample in conn.stream_samples(query, mapping):
    print(sample)
```

### Configuration

Database connection settings are configured via environment variables or the `DBSettings` class:

```bash
# SQLite file database
export DB_URL="sqlite:///./data/training.db"

# In-memory SQLite (default)
export DB_URL="sqlite:///:memory:"
```

Or in your `.env` file:

```env
DB_URL=sqlite:///./data/training.db
```

### CLI Usage

```bash
# Stream samples as JSONL
python connectors/db_connector.py \
    --query "SELECT question AS q, answer AS a FROM qa" \
    --mapping '{"input":"q","output":"a"}'

# Limit output
python connectors/db_connector.py \
    --query "SELECT question, answer FROM qa" \
    --mapping '{"input":"question","output":"answer"}' \
    --limit 10

# Specify database URL
python connectors/db_connector.py \
    --db-url "sqlite:///./data/qa.db" \
    --query "SELECT question, answer FROM qa" \
    --mapping '{"input":"question","output":"answer"}'
```

Using the connector CLI:

```bash
# Test connection
python connectors/cli.py test-connection --db-url "sqlite:///./data/qa.db"

# Stream samples
python connectors/cli.py db-stream \
    --query "SELECT question, answer FROM qa" \
    --mapping '{"input":"question","output":"answer"}'
```

### Column Mapping

The `mapping` parameter specifies which database columns correspond to training sample fields:

```python
# Direct column mapping
mapping = {"input": "question", "output": "answer"}

# With SQL aliases
query = "SELECT q AS question, a AS answer FROM faq"
mapping = {"input": "question", "output": "answer"}
```

### Output Format

Each sample includes metadata about its source:

```json
{
    "input": "How do I reset my password?",
    "output": "Go to Settings > Reset Password.",
    "metadata": {
        "source": "db",
        "raw_row": {
            "question": "How do I reset my password?",
            "answer": "Go to Settings > Reset Password."
        }
    }
}
```

### Row Mapping Utility

The `row_to_sample` function converts individual database rows to training samples:

```python
from connectors.mappers import row_to_sample

row = {"question": "What is 2+2?", "answer": "4", "category": "math"}
mapping = {"input": "question", "output": "answer"}

sample = row_to_sample(row, mapping)
```

### Error Handling

```python
from connectors.db_connector import DBConnector
from connectors.mappers import row_to_sample

# Missing column in mapping
try:
    row_to_sample(row, {"input": "nonexistent"})
except KeyError as e:
    print(f"Mapping error: {e}")

# Database connection issues
conn = DBConnector(db_url="sqlite:///nonexistent.db")
if not conn.test_connection():
    print("Connection failed")
```

### Local Development with SQLite

Create a test database for development:

```python
import sqlite3

conn = sqlite3.connect("./data/test.db")
cursor = conn.cursor()
cursor.execute("""
    CREATE TABLE qa (
        question TEXT,
        answer TEXT
    )
""")
cursor.execute("INSERT INTO qa VALUES (?, ?)",
               ("How do I reset my password?", "Go to Settings > Reset Password."))
conn.commit()
conn.close()
```

Then stream from it:

```bash
export DB_URL="sqlite:///./data/test.db"
python connectors/db_connector.py \
    --query "SELECT question, answer FROM qa" \
    --mapping '{"input":"question","output":"answer"}'
```

## Google Docs Connector

The Google Docs connector fetches and extracts text content from Google Docs. It includes a **mock mode** for offline development and testing.

### Quick Start

```python
from connectors.google_docs_connector import fetch_doc_text, list_docs_in_folder

# Fetch document text (uses mock mode by default)
text = fetch_doc_text("sample_doc1")
print(text)

# List available documents
docs = list_docs_in_folder("any_folder_id")
for doc in docs:
    print(f"{doc['id']}: {doc['title']}")
```

### Mock Mode (Default)

By default, the connector runs in mock mode (`GOOGLE_OAUTH_DISABLED=true`). In this mode, it reads from local sample files instead of making API calls.

Mock mode uses sample files from `examples/google_docs_samples/`:
- `sample_doc1.txt` - Sample documentation content
- `sample_doc2.txt` - Sample FAQ content

### Configuration

```bash
# Mock mode (default) - uses local sample files
export GOOGLE_OAUTH_DISABLED=true

# Real mode - uses Google Docs API (requires OAuth setup)
export GOOGLE_OAUTH_DISABLED=false
```

Or use the `CONNECTOR_MOCK` environment variable:

```bash
# Enable mock mode for all connectors
export CONNECTOR_MOCK=true
```

### CLI Usage

```bash
# Fetch a sample document (mock mode)
python connectors/google_docs_connector.py --doc-id sample_doc1

# List available sample documents
python connectors/google_docs_connector.py --doc-id sample_doc1 --list-samples
```

### Setting Up Google OAuth (Real Mode)

To use the connector with real Google Docs:

1. **Create a Google Cloud Project**
   - Go to [Google Cloud Console](https://console.cloud.google.com/)
   - Create a new project or select an existing one

2. **Enable the Google Docs API**
   - Navigate to "APIs & Services" > "Library"
   - Search for "Google Docs API" and enable it
   - Also enable "Google Drive API" for folder listing

3. **Create OAuth Credentials**
   - Go to "APIs & Services" > "Credentials"
   - Click "Create Credentials" > "OAuth client ID"
   - Select "Desktop application" as the application type
   - Download the credentials JSON file

4. **Install Required Dependencies**
   ```bash
   pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib
   ```

5. **Set Environment Variable**
   ```bash
   export GOOGLE_OAUTH_DISABLED=false
   ```

6. **Implement OAuth Flow** (see `connectors/google_docs_connector.py` for guidance)

### Text Utilities

The connector includes utility functions for text processing:

```python
from connectors.google_utils import extract_text_from_html, normalize_text

# Strip HTML tags
html = "<p>Hello <b>world</b>!</p>"
text = extract_text_from_html(html)  # "Hello world!"

# Normalize whitespace
messy = "Too   many    spaces\n\n\n\nand lines"
clean = normalize_text(messy)  # "Too many spaces\n\nand lines"
```

### Error Handling

```python
from connectors.google_docs_connector import fetch_doc_text

try:
    text = fetch_doc_text("nonexistent_doc")
except FileNotFoundError as e:
    print(f"Document not found: {e}")
except RuntimeError as e:
    print(f"API error: {e}")
```

## File Ingestion Connector

The file ingestion connector extracts text content from various document formats.

### Quick Start

```python
from connectors.file_ingest import ingest_file

# Ingest any supported file
text = ingest_file("path/to/document.txt")
text = ingest_file("path/to/document.md")
text = ingest_file("path/to/document.docx")
text = ingest_file("path/to/document.pdf")
```

### Supported Formats

| Format | Extension | Dependency | Notes |
|--------|-----------|------------|-------|
| Plain Text | `.txt` | None (built-in) | UTF-8 encoding by default |
| Markdown | `.md` | None (built-in) | Returns raw markdown (no rendering) |
| Word Document | `.docx` | python-docx | Extracts paragraph text |
| PDF | `.pdf` | PyMuPDF or pdfminer.six | PyMuPDF preferred for speed |

### Installation

TXT and MD files work out of the box. For DOCX and PDF support, install optional dependencies:

```bash
# For DOCX support
pip install python-docx

# For PDF support (choose one)
pip install PyMuPDF        # Recommended: faster, more accurate
pip install pdfminer.six   # Alternative: pure Python
```

### Checking Available Formats

```python
from connectors.file_ingest import get_supported_formats, check_dependencies

# Check what formats are available
formats = get_supported_formats()
print(formats[".pdf"]["available"])  # True if PDF lib installed

# Check which optional dependencies are installed
deps = check_dependencies()
print(deps)
# {'python-docx': True, 'PyMuPDF': True, 'pdfminer.six': False}
```

### Custom Encoding

For TXT and MD files, you can specify a custom encoding:

```python
# Read a file with Latin-1 encoding
text = ingest_file("legacy_doc.txt", encoding="latin-1")
```

### Error Handling

```python
from connectors.file_ingest import ingest_file

try:
    text = ingest_file("document.pdf")
except FileNotFoundError as e:
    print(f"File not found: {e}")
except ValueError as e:
    print(f"Unsupported format: {e}")
except RuntimeError as e:
    print(f"Missing dependency: {e}")
```

### Sample Files

Sample files for testing are available in `examples/files/`:
- `sample.txt` - Plain text sample
- `sample.md` - Markdown sample with headings and formatting
- `sample.docx` - Word document sample (if python-docx installed)
- `sample.pdf` - PDF document sample (if PDF library installed)

## Adding a New Connector

To add a new connector, follow these patterns:

### 1. Create the Connector Module

Create a new file in `connectors/`, e.g., `connectors/notion_connector.py`:

```python
"""
Notion connector for TinyForgeAI.

Provides functionality to fetch content from Notion pages and databases.
"""

import os
from typing import Iterator, Optional


def _is_mock_mode() -> bool:
    """Check if running in mock mode."""
    # Support both connector-specific and global mock env vars
    if os.getenv("NOTION_MOCK", "").lower() in ("true", "1", "yes"):
        return True
    if os.getenv("CONNECTOR_MOCK", "").lower() in ("true", "1", "yes"):
        return True
    return False


def fetch_page_content(page_id: str) -> str:
    """
    Fetch content from a Notion page.

    Args:
        page_id: The Notion page ID.

    Returns:
        The text content of the page.
    """
    if _is_mock_mode():
        return _fetch_page_mock(page_id)
    return _fetch_page_real(page_id)


def _fetch_page_mock(page_id: str) -> str:
    """Mock implementation for testing."""
    # Read from local sample files
    ...


def _fetch_page_real(page_id: str) -> str:
    """Real implementation using Notion API."""
    # Use notion-client library
    ...


def stream_samples(database_id: str, mapping: dict) -> Iterator[dict]:
    """
    Stream training samples from a Notion database.

    Args:
        database_id: The Notion database ID.
        mapping: Column mapping for input/output fields.

    Yields:
        Training sample dicts.
    """
    ...
```

### 2. Add Tests

Create `tests/test_notion_connector.py`:

```python
"""Tests for Notion connector."""

import pytest
from connectors.notion_connector import fetch_page_content


def test_fetch_page_mock_mode(monkeypatch):
    """Test fetching page in mock mode."""
    monkeypatch.setenv("NOTION_MOCK", "true")
    # Create sample file in examples/notion_samples/
    text = fetch_page_content("sample_page1")
    assert len(text) > 0


def test_fetch_page_not_found(monkeypatch):
    """Test error when page not found."""
    monkeypatch.setenv("NOTION_MOCK", "true")
    with pytest.raises(FileNotFoundError):
        fetch_page_content("nonexistent")
```

### 3. Add CLI Support

Add commands to `connectors/cli.py`:

```python
@cli.command("notion-fetch")
@click.option("--page-id", required=True, help="Notion page ID")
def notion_fetch(page_id: str):
    """Fetch content from a Notion page."""
    from connectors.notion_connector import fetch_page_content
    print(fetch_page_content(page_id))
```

### 4. Update Documentation

Add a section to this file documenting the new connector.

## Environment Variables Reference

| Variable | Default | Description |
|----------|---------|-------------|
| `DB_URL` | `sqlite:///:memory:` | Database connection URL |
| `GOOGLE_OAUTH_DISABLED` | `true` | Enable mock mode for Google Docs |
| `CONNECTOR_MOCK` | `false` | Enable mock mode for all connectors |

## Troubleshooting

### Database Connection Fails

```bash
# Check if database file exists
ls -la ./data/

# Test with in-memory database
python -c "from connectors.db_connector import DBConnector; print(DBConnector().test_connection())"
```

### Google Docs Mock File Not Found

```bash
# Check if sample files exist
ls -la examples/google_docs_samples/

# Verify GOOGLE_OAUTH_DISABLED is set
echo $GOOGLE_OAUTH_DISABLED
```

### PDF/DOCX Ingestion Fails

```bash
# Check which dependencies are installed
python -c "from connectors.file_ingest import check_dependencies; print(check_dependencies())"

# Install missing dependencies
pip install python-docx PyMuPDF
```

### Unicode/Encoding Errors

```python
# Specify encoding explicitly
from connectors.file_ingest import ingest_file
text = ingest_file("file.txt", encoding="utf-8-sig")  # For files with BOM
text = ingest_file("file.txt", encoding="latin-1")    # For legacy files
```

## Related Documentation

- [Training Documentation](training.md) - Using connectors with training pipeline
- [Architecture Overview](architecture.md) - System design and components
- [CI/CD](ci.md) - Continuous integration setup
